Up until now we've opened image files or videos directly by using native functionalities of OpenCV (cv2) python library.
However, the images or video stream in ROS is published onto topics, and is not coming directly from a camera device or a media file for which
opencv already had provisions to read from.

So we will be receiving images in ROS environment through various ROS topics. So in this case, we need to create a subscriber in ROS in order to
recieve the image and then processing this image with help of opencv.
However there's one challenge that the image format supported by the ROS is not supported by the OpenCV and hence there's need to transform
any incoming image through ROS topics to that of suitable format to be processed by OpenCV library and vice versa when we want to publish an image
generated/processed by opencv.

It is specifically for this reason, there exist a specifc code component called CVBridge which allows us to make this conversion.

Schematically ---

[OpenCV cv::Mat] <---> [CvBridge] <---> [ROS Image Message]
					   [          ROS ECOSYSTEM 		  ]

# Note - to see the following python script in action, you're going to need to insert your webcam/usbcam into the ROS enviroment.
# usb_cam is ros package to get images from the computer camera and publish them onto a ros topic called /usb_cam/Image_raw
# you can run following node with given argument to accomplish this -
# rosrun usb_cam usb_cam_node _pixel_format:=yuyv
# you can view a video feed in ROS environment itself using
# rosrun image_view image_view image:="name of the image topic you want to see"



Python code for bridging OpenCV and ROS -

<code>
#! /usr/bin/env python

import rospy, cv2, sys
from std_msgs.msg import String
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError

bridge = CvBridge()

def image_callback(ros_image):

	# if you look at the documentation of sensor_msgs.msg.Image message, you'll find that all the data of the image
	# is carried as a single dimensional array of unsigned integers, while other fields of the image
	# carry critical enfomation to decode that single dimensional array into appropriate format which are height, width of image
	# and encoding of the image. There are also headers which hold the timestamps and other bits of information.
	
	print("Recieved an Image")
	
	try:
		image = bridge.imgmsg_to_cv2(ros_image, "bgr8")
		# convert to bgr format with unit8 datatype for each channel
	except CvBridgeError as e:
		print(e)
	# from this point onwards, you can work on image object with cv2 library as usual
	rows, columns, channels = image.shape
	if columns > 200 and rows > 200:
		cv2.circle(image, (100, 100), 90, 255)
	font = cv2.FONT_HERSHEY_SIMPLEX
	cv2.putText(image, "Webcam Activated with ROS and OpenCV!", (10, 350), font, 1, (255, 0, 255), 2, cv2.LINE_AA)
	cv2.imshow("Image Window", image)
	cv2.waitKey(3)


def main(args):
	rospy.init_node("image_converter", anonymous=True)
	# for turtlebot3 waffle
	# image topic = "/camera/rgb/image_raw/compressed"
	# for usb cam
	# image topic = "/usb_cam/image_raw"
	# for the webcam image topic = "/camera/image_raw"
	image_sub = rospy.Subscriber("/camera/image_raw/", Image, image_callback)
	try:
		rospy.spin()
	except KeyboardInterrupt:
		print("Terminating...")
	cv2.destroyAllWindows()


if __name__ == "__main__":
	main(sys.argv)
</code>
